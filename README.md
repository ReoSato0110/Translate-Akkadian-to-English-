## 目的
- Kaggle Deep Past Challengeでのメダル獲得
- 再現可能なDeep Learningパイプラインの構築

## アプローチ概要
- ベースラインとして〇〇モデルを採用
- 前処理 → 学習 → 評価 → 推論を一貫したコードで管理
- 再現性を最優先
→構造・ソースをローカルで整理し、実行・実験をkaggle notebookで行う。
## 学び・仮説
- 評価指標のBLEUは、「どれだけ“連続した単語の塊”が一致しているか」。*意味は見ない
  - 語順
  - 機能語（a / the / of / to / is / was など）
  - 定型フレーズ
  - 表記の癖（記号・長音・特殊文字）
---
- 短い文ズル対策：Brevity Penalty
  　　短ければ一致率が高くなる逃げを防ぐ。

- Dice係数（辞書確率）:強い対応関係を明確化する。(not 頻度)

  (例：score = 2 * c / (src_cnt[sw] + tgt_cnt[tw]
  「このアッカド語単語 sw がこの英語単語 tw と一緒に出る確率」を測っている。)
---
- ベースライン構築
- byT5-baseで通し。


### <上位者notebook>
- コンペ：定型句が多い、似た石版が大量にある
→類似文検索の相性が良く、ルールベースのTF-IDF検索が用いられている。
